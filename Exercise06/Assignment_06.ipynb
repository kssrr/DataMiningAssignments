{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining: Basic Concepts - Winter 2023/24\n",
    "---------------\n",
    "``` \n",
    "> University of Konstanz \n",
    "> Department of Computer and Information Science\n",
    "> Maximilian T. Fischer, Frederik Dennig, Yannick Metz, Udo Schlegel\n",
    "```\n",
    "__Organize in teams of 2 people, return the exercise on time using ILIAS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 06 in Python \n",
    "---------------\n",
    "- ___Please put your names and student IDs here___:\n",
    "    - _Name_, _Student ID_\n",
    "    - _Name_, _Student ID_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: The role of Kernels in Support Vector Machines \n",
    "In this exercise we want to investigate why we use kernels in SVMs, and how they work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Make sure to have the plotting_utils.py file in the same folder as this notebook.</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "%matplotlib inline\n",
    "from plotting_utils import make_blobs, plot_2d_separator, discrete_scatter "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Given is the following dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to change anything here\n",
    "c=['b', 'r', 'g']\n",
    "X, y = make_blobs(centers=4, random_state=8)\n",
    "y = y % 2\n",
    "\n",
    "discrete_scatter(X[:, 0], X[:, 1], y, c=c)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit a linear SVM (`LinearSVC` in the scikit-learn) to this dataset. Plot both the data and the resulting decision boundary. You can use the function plot_2d_separator from the plotting_utils.py file by just calling `plot_2d_separator(trained_model, X)`to draw the decision boundary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe what the issue is with the given data.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with differente kernels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) What is the idea of the kernel trick? What is an RBF kernel? Give a brief explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Now let's use a kernel SVM to fit the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a kernel SVM to the dataset from above. Use an `Radial Basis Function` kernel.\n",
    "You can use the default `SVC` from scikit-learn. Plot both the dataset the decision boundary of the SVM using the `plot_2d_separator(trained_model, X)`. Try to also visualize the support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you observe?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Forward Pass in a Multilayer Neural Networks\n",
    "\n",
    "You are given the following feed-forward neural network containing 2 input neurons, 2 hidden neuron and 1 output neurons:\n",
    "\n",
    "![network.png](network.png)\n",
    "\n",
    "w1 to w6 represent the weights of the connections between the neurons. Their exact values can be found in this table:\n",
    "\n",
    "|Weight|Value|\n",
    "|-----|------|\n",
    "|w1|-0.7|\n",
    "|w2|0.6|\n",
    "|w3|-0.4|\n",
    "|w4|0.6|\n",
    "|w5|-0.3|\n",
    "|w6|1.0|\n",
    "\n",
    "Non-input Neuron also have a Bias shown in this table:\n",
    "\n",
    "\n",
    "|Neuron|Bias|\n",
    "|-----|-----|\n",
    "|N3|0.6|\n",
    "|N4|0.1|\n",
    "|N5|-1.3|\n",
    "\n",
    "Assume a sigmoidal activation function $g(x) = 1 / (1+e^{-x})$ in each Neuron.\n",
    "\n",
    "Calculate the Input and Output of N3, N4 and N5 with input:\n",
    "\n",
    "|Neuron|Input|\n",
    "|-----|-----|\n",
    "|N1|-1.5|\n",
    "|N2|3.0|\n",
    "\n",
    "_(Hint: Input Neurons do not use the activation function. The Output of N1 and N2 are therefore the same as their respective Inputs.)_\n",
    "\n",
    "__For this exercise, you can cut each result at the third digit after the dot. (e.g. 0.12345 becomes 0.123)__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input N3:\n",
    "\n",
    "Output N3:\n",
    "\n",
    "Input N4:\n",
    "\n",
    "Output N4:\n",
    "\n",
    "Input N5:\n",
    "\n",
    "Output N5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Perceptron Implementation\n",
    "\n",
    "In this exercise, the task is to implement a Perceptron algorithm in Python. Below, we give a bi-dimensional dataset and the class values.\n",
    "\n",
    "\n",
    "\n",
    "|X    |Y    |Class(OR)|Class(AND)|\n",
    "|-----|-----|---------|---------|\n",
    "| 0 | 0 | 0 | 0 |        \n",
    "| 0 | 1 | 1 | 0 |\n",
    "| 1 | 0 | 1 | 0 |\n",
    "| 1 | 1 | 1 | 1 |\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(a) In your implementation of a Perceptron, build a Python Class `Perceptron` with the following methods and inputs:__\n",
    "* Constructor: `__init__(self, learning_rate, number_iterations)`\n",
    "* Learning funtion: `learn(self, X, y)` where `X` is the training example data as a 2D `numpy.array`and `y`is the training data labels example as a  a 1D `numpy.array`\n",
    "* Predict function: `predict(self, x)` where `x` is a  1D `numpy.array` with the data that should be classified  \n",
    "* learning rate\n",
    "\n",
    "_Your function should print the weights for each iteration and data point._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron():\n",
    "\n",
    "    # Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(b) Run your Perceptron and set an initial value for the learning rate, the weights (e.g., `<0,0,0>`) and number of iterations. Check the for the OR and AND class the correctness of the classification outputs.__\n",
    "\n",
    "(Hint: Make sure the learning rate is not too high, otherwise the algorithm will not converge.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    [0., 0.],\n",
    "    [1., 0.],\n",
    "    [0., 1.],\n",
    "    [1., 1.]\n",
    "]\n",
    "\n",
    "X = np.array(inputs)\n",
    "y_or = np.array([0, 1, 1, 1])\n",
    "y_and = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Perceptron(0.01, 5) \n",
    "\n",
    "p.learn(X, y_or)\n",
    "for i, e in zip(inputs, y_or):\n",
    "    print(f\"{i} --> {p.predict(i)}. Excepted {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(d) When using your perceptron implementation, try to train a model, which classifies the XOR gate `<0,1,1,0>`. Comment on the result and try to explain why it does not work.__\n",
    "\n",
    "|X    |Y    |Class(XOR)|\n",
    "|-----|-----|---------|\n",
    "| 0 | 0 | 0 |       \n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docana_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "116075abdc1ed53ddb80f9e3462a1a87c17f9d858d16aae38864710ebb8faa39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
