{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining: Basic Concepts - Winter 2023/24\n",
    "---------------\n",
    "``` \n",
    "> University of Konstanz \n",
    "> Department of Computer and Information Science\n",
    "> Maximilian T. Fischer, Frederik Dennig, Yannick Metz, Udo Schlegel\n",
    "```\n",
    "__Organize in teams of 2 people, return the exercise on time using ILIAS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 08 in Python \n",
    "---------------\n",
    "- ___Please put your names and student IDs here___:\n",
    "    - ___Please put your names and student IDs here___:\n",
    "    - _Lorenz Rückert_, _01/911915_\n",
    "    - _Lennart Kasserra_, _01/1358216_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 1: Lazy vs Eager: Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Explain the difference between an eager learner and a lazy learner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While an eager learner learns an abstract model based on a training set, which it uses to classify new observations, lazy learners store data tuples and classify newly encountered tuples based on the already stored data tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Provide an example of a machine learning algorithm that is an eager learner and one that is a lazy learner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume a classification context. Decision Trees would be an example of an eager learner - first they are trained on a training set, forming decision rules. Newly encountered observations are then classified based on these learned decision rules.\n",
    "\n",
    "An example of a lazy learner would be k-Nearest Neighbor (kNN) classification: upon encountering a new tuple, the k known tuples with the shortest distance to the new tuple are detected & their most common class is assigned to the new tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You are given a dataset with 1 million rows and 10 columns. You need to build a machine learning model to predict a binary outcome based on the values in the columns. You have two options: a decision tree or a k-nearest neighbors algorithm.*\n",
    "  \n",
    "**b) Which algorithm should you choose and why? Explain your reasoning in detail, taking into account the size and complexity of the dataset and the computational resources available to you.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use a decision tree. Decision trees are inexpensive to construct, which is advantageous given the size and complexity of the data. It would be computationally expensive to run a kNN-query on 1 million rows and 10 columns for every input. A decision tree would also be advantageous in terms of interpretability, as kNN does not generate any explicit knowledge about the classes (although interpretability would probably, to some point, be impaired by the complexity of the data set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 2: Lazy vs Eager: Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we want to implement a basic k-nearest neighbor algorithm.   \n",
    "For this, we need a similarity function and a general k-nearest neighbor function.  \n",
    "We will use the breast cancer dataset we previously used for the SVM with an 80/20 train test split.    \n",
    "  \n",
    "**Please implement the k-nearest neighbor algorithm on your own and show that the implementation works for the breast cancer data.**  \n",
    "_(Hint: use the `sklearn.model_selection.train_test_split` method and the parameter `random_state=0`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "df['diagnosis'] = data.target\n",
    "\n",
    "features = list(data.feature_names)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance is bad, but it is made with passion:\n",
    "\n",
    "class KNNClassifier:\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    def __init__(self, k: int) -> None:\n",
    "        self.k = k\n",
    "\n",
    "    def train(self, train_features: pd.DataFrame, train_target: pd.Series) -> None:\n",
    "        self.train_features = train_features\n",
    "        self.train_target = train_target\n",
    "\n",
    "    def __euclidean_dist(self, new_tup, known_tup):\n",
    "        return np.sqrt(sum((new_tup - known_tup)**2))\n",
    "    \n",
    "    def predict(self, test_features: pd.DataFrame) -> list:\n",
    "        \n",
    "        predictions = []\n",
    "\n",
    "        for _, row in test_features.iterrows():\n",
    "            # find closest rows:\n",
    "            distances = [self.__euclidean_dist(row, xrow) for _, xrow in self.train_features.iterrows()]\n",
    "            ids = sorted(range(len(distances)), key=lambda sub: distances[sub])[:self.k]\n",
    "            # find their classes & store most frequent one:\n",
    "            values = self.train_target.iloc[ids]\n",
    "            prediction = values.mode()[0]\n",
    "            predictions.append(prediction)\n",
    "\n",
    "\n",
    "        self.predictions = predictions\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, test_target: pd.Series) -> float:\n",
    "        return sum(self.predictions == test_target) / len(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just showing it works with some k (albeit very slowly):\n",
    "knn = KNNClassifier(k=5)\n",
    "knn.train(train[features], train[\"diagnosis\"])\n",
    "knn.predict(test[features]) # predictions are stored in knn.predictions...\n",
    "knn.evaluate(test[\"diagnosis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 3: Evaluation Metrics Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Explain why different evaluation metrics are used for evaluating the performance of classifiers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different metrics reflect different tradeoffs and have different strengths. For example, ROC curves are better fit for when observations are balanced between classes, while Precision & Recall are more appropriate for imbalanced data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Provide examples of common evaluation metrics for classification algorithms, and explain the strengths and limitations of each metric in the context of classifier evaluation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Precision & Recall:** *Precision* represents the ability of a system to present only relevant items, while *Recall* is a measure of the ability of a system to present all relevant items. They represent the tradeoff between the true positive rate and the positive predictive value of a model.\n",
    "\n",
    "* **ROC:** *ROC* (Receiver Operating Characteristic) summarises the tradeoff between the true positive rate, and the false positive rate for a model.\n",
    "\n",
    "While ROC curves are better fit for when observations are balanced between classes, Precision & Recall are appropriate for imbalanced data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Explain how a perfect precision-recall curve looks like.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect precision-recall curve maximizes both precision and recall; we would like the curve to stay as close to a value of 1 as possible for both of these; in the conventional way of visualizing, we would expect the curve to pivot towards the top right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 4: Evaluation Metrics Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After thinking about the different evaluation metrics, we want to see them in real-world scenarios and inspect their workings.  \n",
    "We tackle two datasets for this task and use the machine learning algorithms we have already explored.  \n",
    "The first dataset will be the breast cancer dataset again. The second one will be the cover-type forest dataset.  \n",
    "Both datasets have unique properties and need special care. Handling different data is not always easy and selecting proper algorithms is even more challenging.\n",
    "Thus, we focus on the different evaluation metrics to select one good working algorithm.  \n",
    "In this case, we will compare the sci-kit learn implementations of Naive Bayes, Decision Trees, SVMs, and k-Nearest Neighbors based on the classification accuracy and F1-score.  \n",
    "  \n",
    "As the cover type data has more than two classes, we will only use the second and third class samples.  \n",
    "  \n",
    "**Please implement a comparison between the sci-kit learn implementations of Naive Bayes, Decision Trees, SVMs, and k-Nearest Neighbors on the breast cancer data and cover type data for your own implementation of accuracy and F1-score.**    \n",
    "_(Hint: use the `sklearn.model_selection.train_test_split` method and the parameter `random_state=0`)_  \n",
    "_(Hint: use the `sklearn.naive_bayes.GaussianNB`, `sklearn.tree.DecisionTreeClassifier`, `sklearn.svm.SVC`, `sklearn.neighbors.KNeighborsClassifier` methods with default parameters)_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*First we do it for the forest cover:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "data = fetch_covtype()\n",
    "\n",
    "target = data['target'][np.logical_or(data['target'] == 2, data['target'] == 3)] - 2\n",
    "data = data['data'][np.logical_or(data['target'] == 2, data['target'] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features = train_test_split(data, test_size=0.2, random_state=0)\n",
    "train_target, test_target = train_test_split(target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "for model in [naive_bayes, decision_tree, svm, knn]:\n",
    "    model.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\n",
    "    \"naive_bayes\":   naive_bayes.predict(test_features),\n",
    "    \"decision_tree\": decision_tree.predict(test_features),\n",
    "    \"svm\":           svm.predict(test_features),\n",
    "    \"knn\":           knn.predict(test_features)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_metrics(actual, predicted):\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    TP, FP, FN, TN = cm.ravel()\n",
    "    accuracy = (TP + TN) / len(actual)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.915203</td>\n",
       "      <td>0.949890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.995017</td>\n",
       "      <td>0.997193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.964285</td>\n",
       "      <td>0.980074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.998455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  accuracy        f1\n",
       "0    naive_bayes  0.915203  0.949890\n",
       "1  decision_tree  0.995017  0.997193\n",
       "2            svm  0.964285  0.980074\n",
       "3            knn  0.997258  0.998455"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_metrics = []\n",
    "for model, pred in predictions.items():\n",
    "    metrics = get_metrics(test_target, pred)\n",
    "    all_model_metrics.append({\"model\": model, \"accuracy\": metrics[\"accuracy\"], \"f1\": metrics[\"f1\"]})\n",
    "\n",
    "metrics_forest = pd.DataFrame(all_model_metrics)\n",
    "metrics_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, kNN has the highest accuracy, and the highest f1-score, closely followed by the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Next, we jump to the breast cancer dataset:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "df['diagnosis'] = data.target\n",
    "target = \"diagnosis\"\n",
    "\n",
    "features = list(data.feature_names)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes2 = GaussianNB()\n",
    "decision_tree2 = DecisionTreeClassifier()\n",
    "svm2 = SVC()\n",
    "knn2 = KNeighborsClassifier()\n",
    "\n",
    "for model in [naive_bayes2, decision_tree2, svm2]:\n",
    "    model.fit(train[features], train[target])\n",
    "\n",
    "# kNN needs special treatment when dealing with pandas objects\n",
    "knn2.fit(train[features].values, train[target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\n",
    "    \"naive_bayes\":   naive_bayes2.predict(test[features]),\n",
    "    \"decision_tree\": decision_tree2.predict(test[features]),\n",
    "    \"svm\":           svm2.predict(test[features]),\n",
    "    \"knn\":           knn2.predict(test[features].values)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.884211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  accuracy        f1\n",
       "0    naive_bayes  0.903509  0.884211\n",
       "1  decision_tree  0.903509  0.888889\n",
       "3            knn  0.964912  0.955556\n",
       "2            svm  0.973684  0.967742"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_metrics = []\n",
    "for model, pred in predictions.items():\n",
    "    metrics = get_metrics(test[target], pred)\n",
    "    all_model_metrics.append({\"model\": model, \"accuracy\": metrics[\"accuracy\"], \"f1\": metrics[\"f1\"]})\n",
    "\n",
    "metrics_cancer = pd.DataFrame(all_model_metrics)\n",
    "metrics_cancer.sort_values(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the SVM outperforms the other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "116075abdc1ed53ddb80f9e3462a1a87c17f9d858d16aae38864710ebb8faa39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
