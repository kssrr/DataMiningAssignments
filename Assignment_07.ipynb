{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Data Mining: Basic Concepts - Winter 2023/24\n",
    "---------------\n",
    "``` \n",
    "> University of Konstanz \n",
    "> Department of Computer and Information Science\n",
    "> Maximilian T. Fischer, Frederik Dennig, Yannick Metz, Udo Schlegel\n",
    "```\n",
    "__Organize in teams of 2 people, return the exercise on time using ILIAS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Assignment 07 in Python\n",
    "---------------\n",
    "- ___Please put your names and student IDs here___:\n",
    "    - _Name_, _Student ID_\n",
    "    - _Name_, _Student ID_\n",
    "---    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input N3:\n",
    "\n",
    "Output N3:\n",
    "\n",
    "Input N4:\n",
    "\n",
    "Output N4:\n",
    "\n",
    "Input N5:\n",
    "\n",
    "Output N5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Classifying Hand-Written Digits with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Getting Started\n",
    "\n",
    "This exercise will give a short introduction into the framework PyTorch (https://pytorch.org/) to build small and large neural networks.\n",
    "\n",
    "PyTorch is an open-source deep learning framework that’s known for its flexibility and ease-of-use. This is enabled in part by its compatibility with the popular Python high-level programming language favored by machine learning developers and data scientists.\n",
    "\n",
    "##### What is PyTorch?\n",
    "\n",
    "PyTorch is a fully featured framework for building deep learning models, which is a type of machine learning that’s commonly used in applications like image recognition and language processing. Written in Python, it’s relatively easy for most machine learning developers to learn and use. PyTorch is distinctive for its excellent support for GPUs and its use of reverse-mode auto-differentiation, which enables computation graphs to be modified on the fly. This makes it a popular choice for fast experimentation and prototyping.\n",
    "\n",
    "##### Key Benefits of PyTorch\n",
    "\n",
    "- There’s a large and vibrant community at PyTorch.org community with excellent documentation and tutorials. The forums are active and supportive.\n",
    "- It’s written in Python and integrated with popular Python libraries like NumPy for scientific computing, SciPy, and Cython for compiling Python to C for better performance. Because its syntax and usage are similar to Python’s, PyTorch is relatively easy for Python developers to learn.\n",
    "- It supports CPU, GPU, and parallel processing, as well as distributed training. This meana that computational work can be distributed among multiple CPU and GPU cores, and training can be done on multiple GPUs on multiple machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Please install the `torch` and `torchvision` packages, ideally by following the setup guide: (https://pytorch.org/get-started/locally/).__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### More Information: \n",
    " \n",
    "You can find many resources on how to get started with PyTorch, both in written form or as videos.\n",
    "In this exercise, we want to give a brief introduction. You will learn how to:\n",
    "\n",
    "1. How to create a model. \n",
    "2. How to select an optimizer, a loss function and a metric. \n",
    "3. How to train the model on data. \n",
    "4. How to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1:  Build your first small Neural Network \n",
    "\n",
    "__In this exercise we will use a Neural Network on a real data set. We will classify the digits dataset (MINST)__\n",
    "\n",
    "You are allowed to use the following packages only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can keep the following parameters for training and testing\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### __(a) Load the MNIST dataset via the torchvision dataset functionality. Load both the training and test data__\n",
    "_(Hint: use the `DataLoader` from torch and `datasets.MNIST` class from the torch library, Create a separate dataloader for training and testing.)_\n",
    "\n",
    "- Use a batch size of 64 for training, and 1000 for testing (You can just the parameters before)\n",
    "- You can pass a transform the PyTorch dataloaders to perform pre-processing of the data, use `torchvision.transforms.Compose` to chain the processing steps of `torchvision.transforms.ToTensor()`(converting images to PyTorch tensors) and `torchvision.transforms.Normalize((0.1307,), (0.3081,))` (normalize the data with mean and std. of the MNIST dataset)\n",
    "- Make sure to shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### __(b) Quickly describe what the MMNIST dataset is. If you like, you can also visualize samples from the dataset.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### __(c) Create the neural network to train.__\n",
    "\n",
    "Create a network with the `torch.nn` package. The package contains many different layers with can be composed into complex neural networks.\n",
    "- Create a class `Net` that inherits from `nn.Module`.\n",
    "- Specify the layers you want to use in the `__init__(self)` method of the class.\n",
    "- Define the `forward(self, x)` to define how the output is computed given the input `x` and layers you specified in the init\n",
    "\n",
    "You have ***two options*** for your network. Choose either one:\n",
    "\n",
    "1. Use this given architecture: A CNN network architecture containing the following layers:\n",
    "- A first `Conv2d` layer with kernel size 5, 10 filters, and stride 2\n",
    "- A `nn.RELU()` activation layer\n",
    "- A second `Conv2d` layer with kernel size 5 and 20 filters, and stride 2\n",
    "- A `nn.RELU()`activation layer\n",
    "- A first fully connected (`linear`) layer with 320 input neurons and 50 output neurons\n",
    "- A final `nn.RELU()` activation layer\n",
    "- A second fully connected layer with 50 input neurons and 10 output neurons (corresponding to the number of classes)\n",
    "- A softmax layer that turns the network activations into class probabilities\n",
    "\n",
    "2. Choose and implement your own network architecture. You are completely free in choosing a architecture you build from layers of the `nn` package. As the only condition, your network should achieve a test accuracy of at least 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(d) Initialize the network (by calling the empty constructor) and create the optimizer (`optim.SGD`) by passing the network parameters.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "network = Net()\n",
    "\n",
    "# Code here: Initialize the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### __(f) We now train the neural network on the training data set and predict the test data set. For this, we have implemented the train and test functions for you. If you did the previous task correctly, this code should run without errors.__\n",
    "\n",
    "In this exercise, you task is to understand the given code. Try to ***fill the empty comments marked by `Explanation:`*** in the following code blocks. You can use any online ressources you like as reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train(epoch): \n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # Explanation: <Here>\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target) # Explanation: <Here>\n",
    "        loss.backward() # Explanation: <Here>\n",
    "        optimizer.step() # Explanation: <Here>\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval() # Explanation: <Here>\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # Explanation: <Here>\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item() # Explanation: <Here>\n",
    "            pred = output.data.max(1, keepdim=True)[1] # Explanation: <Here>\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(g) Run training and testing and describe the output.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation should be compatible with the following code\n",
    "\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(g) We have saved traning statistics in the train_losses/test_losses lists. Plot the training and test accuracy values during training. You can use any plotting library, e.g. matplotlib or seaborn.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Interpret the results***\n",
    "\n",
    "Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "> Your Answer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Use all the transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned in the lecture, nowadays, transformers are the way to go.    \n",
    "Large language models such as GPT2 and GPT3 are currently state-of-the-art for a lot of natural language processing.  \n",
    "Now, we want to look at how hard or easy it is to work with these models.  \n",
    "So, we start with a smaller model, the [GPT2 model](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), and use it for some text generation using the hugging face (https://huggingface.co/) [packaging](https://huggingface.co/docs/transformers/model_doc/gpt2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Please install the `transformers` packages, ideally by following the setup guide: (https://huggingface.co/docs/transformers/installation).__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __a) Load the `gpt2` (https://huggingface.co/gpt2) model from the `transformers` package and generate some follow up to 'Hi, I am a transformer, I can'.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __b) Use your previous code and change the `temperature`. Which changes do you see?__\n",
    "_(Hint: use the `temperature` keyword parameter in the `generator` to achieve this.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "> Your Answer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
